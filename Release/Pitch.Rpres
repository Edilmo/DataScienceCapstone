Data Science Capstone Project 
========================================================
author: Edilmo Palencia
date: 04/24/2016

Last Word Prediction

Introduction
========================================================

The original purpose of the project was to develop an N-gram model to predict the next word, given a piece of text.
During the 'analysis phase' of the project, it was concluded that a more practical and concrete application to the original objective of 'Predicting the next word' could be achieved by narrowing it down to finer-grained objectives:  
1.- Complete the given sentence or paragraph with its last word.
2.- Suggest the complete sentence or paragraph that is most likely, given a fragment of text.

Based on the evaluation criteria, this application tackles the prediction of the next word considering the case previously described in 1; i.e., the last word in a sentence.

Justification
========================================================

**Practical perspective**  
In order to simplify the scope, a 'practical' application was considered. Consider 'google'. Whenever a user is typing under the 'search box', the auto-complete feature makes a proper suggestion of the next word. In practice, the best bet is to assume that the 'next' word is actually the 'last' word, this significantly reduces the scope of the problem and thus, improves time of response.  
**Theoretical perspective**  
N-gram models are derived from a Markov Processes that run infenitelly. In reality, people does not produce infinite sequences. Instead, people produce emsembles of sequences that are related to each other. In this work the Markov Process is considered to have a Martingale Process associated and the next word to predict is a 'Stopping Time' in the whole stochastic process. 

Description of the Algorithm
========================================================
The algorithm is considering the sequence be generated by a Markov Process that is also a sub-martingale process where the conditions of the 'Optional stopping theorem' theorem also holds.
With this considerations the algorithm makes the prediction of the last word based mainly in the last 3 words and the first 3 words. This is thanks to the faxct that in a process with the characteristics described before, is posible to compute the expected for the last word based on the value of the first one.



Description of the App
========================================================

A simple shinny app was developed in order to test the algorithm.
The app includes:  
- A input box that received the text to complete.  
- A table with the best candidates words predicted by the algorithm  
